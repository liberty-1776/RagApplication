{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b564377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import streamlit as st\n",
    "from langchain_ollama import ChatOllama\n",
    "import shutil\n",
    "## We will be suing Titan Embeddings Model To generate Embeddings\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "## Data Ingestion and Transformatioin\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader,PyPDFLoader\n",
    "\n",
    "\n",
    "# Vector Embedding And Vector Store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "## LLm Models\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA,ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86bac074",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock=boto3.client(service_name=\"bedrock-runtime\")\n",
    "bedrock_embeddings=BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",client=bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1430a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "deepSeek=ChatBedrock(model_id=\"arn:aws:bedrock:ap-south-1:217522444118:inference-profile/apac.amazon.nova-pro-v1:0\",client=bedrock,model_kwargs={'maxTokens':512,'model_provider':\"amazon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc884e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatBedrock(client=<botocore.client.BedrockRuntime object at 0x168fa5700>, bedrock_client=<botocore.client.Bedrock object at 0x169484fb0>, model_id='arn:aws:bedrock:ap-south-1:217522444118:inference-profile/apac.amazon.nova-pro-v1:0', model_kwargs={}, max_tokens=512, beta_use_converse_api=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deepSeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42718ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama=ChatBedrock(model_id=\"meta.llama3-70b-instruct-v1:0\",client=bedrock,\n",
    "                model_kwargs={'max_gen_len':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74034525",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Model provider should be supplied when passing a model ARN as model_id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mdeepSeek\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHello, explain quantum physics simply.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:395\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    391\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    392\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m--> 395\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    405\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1023\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1021\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m   1022\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m-> 1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:805\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m ls_structured_output_format \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mls_structured_output_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    800\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstructured_output_format\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    801\u001b[0m ls_structured_output_format_dict \u001b[38;5;241m=\u001b[39m _format_ls_structured_output(\n\u001b[1;32m    802\u001b[0m     ls_structured_output_format\n\u001b[1;32m    803\u001b[0m )\n\u001b[0;32m--> 805\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_invocation_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m options \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m: stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mls_structured_output_format_dict}\n\u001b[1;32m    807\u001b[0m inheritable_metadata \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(metadata \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ls_params(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[1;32m    810\u001b[0m }\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:700\u001b[0m, in \u001b[0;36mBaseChatModel._get_invocation_params\u001b[0;34m(self, stop, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_invocation_params\u001b[39m(\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    697\u001b[0m     stop: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    699\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[0;32m--> 700\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m stop\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1432\u001b[0m, in \u001b[0;36mBaseChatModel.dict\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a dictionary of the LLM.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1432\u001b[0m     starter_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_identifying_params\u001b[49m)\n\u001b[1;32m   1433\u001b[0m     starter_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm_type\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m starter_dict\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_aws/llms/bedrock.py:814\u001b[0m, in \u001b[0;36mBedrockBase._identifying_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_identifying_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    810\u001b[0m     _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id,\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_id,\n\u001b[0;32m--> 814\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprovider\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming,\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguardrails\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m),  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrailIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguardrails\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrailIdentifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    818\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrailVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mguardrails\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mguardrailVersion\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    819\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs,\n\u001b[1;32m    820\u001b[0m     }\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ai_development/lib/python3.12/site-packages/langchain_aws/llms/bedrock.py:830\u001b[0m, in \u001b[0;36mBedrockBase._get_provider\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;66;03m# If model_id is an arn, can't extract provider from model_id,\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# so this requires passing in the provider by user\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    831\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel provider should be supplied when passing a model ARN as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_id\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    835\u001b[0m \u001b[38;5;66;03m# If model_id has region prefixed to them,\u001b[39;00m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# for example eu.anthropic.claude-3-haiku-20240307-v1:0,\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# provider is the second part, otherwise, the first part\u001b[39;00m\n\u001b[1;32m    838\u001b[0m parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Model provider should be supplied when passing a model ARN as model_id"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = deepSeek.invoke([HumanMessage(content=\"Hello, explain quantum physics simply.\")])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d91f8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let’s think of the world as a giant stage where everything—particles, light, atoms—plays its part. Quantum physics is the script that tells us how the tiniest actors behave. Here’s a simple, step‑by‑step picture:\n",
      "\n",
      "---\n",
      "\n",
      "## 1. **Tiny is a Whole new world**\n",
      "- **Classical physics** (the physics of everyday life) works perfectly for things you can see: cars, planets, baseballs.\n",
      "- **Quantum physics** governs things that are *tiny*—electrons, photons (particles of light), atoms, and even smaller bits of matter.\n",
      "\n",
      "## 2. **Things are also waves**\n",
      "- In the quantum world, particles act like **waves** too. This is called *wave‑particle duality*.\n",
      "- Imagine throwing a pebble into a pond. The ripple spreads out like a wave. In quantum physics, an electron can spread out in a similar “wave” way, describing where it *might* be.\n",
      "\n",
      "## 3. **Probability, not certainty**\n",
      "- Because of the wave nature, we can’t say exactly where a particle is. We can only talk about the **probability** of finding it in a certain spot.\n",
      "- Think of it like a fuzzy “heat map”: brighter regions mean a higher chance of catching the particle there.\n",
      "\n",
      "## 4. **Quantized energy**\n",
      "- Energy isn’t continuous like a smooth slide; it comes in **discrete packets** called *quanta*.\n",
      "- For example, an electron orbiting an atom can only have specific energy levels—like a ladder with rungs, not a continuous slope.\n",
      "\n",
      "## 5. **Superposition – being in many places at once**\n",
      "- A quantum object can exist in a *superposition* of multiple states simultaneously.\n",
      "- Picture a spinning coin: while it’s in the air, it’s both heads **and** tails. Only when it lands (when we measure) does it pick one outcome.\n",
      "\n",
      "## 6. **Entanglement – spooky connections**\n",
      "- Two particles can become **entangled**, meaning their properties are linked no matter how far apart they are.\n",
      "- If you measure one, you instantly know the state of the other, even if they’re on opposite sides of the universe. Einstein called this “\n"
     ]
    }
   ],
   "source": [
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage\n",
    "import boto3\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=\"ap-south-1\")\n",
    "\n",
    "nova_llm = ChatBedrock(\n",
    "    client=bedrock,\n",
    "    model_id=\"openai.gpt-oss-120b-1:0\", \n",
    "    model_kwargs={\"max_completion_tokens\": 512}\n",
    ")\n",
    "\n",
    "response = nova_llm.invoke([HumanMessage(content=\"Hello, explain quantum physics simply.\")])\n",
    "response = parser.invoke(response)\n",
    "if \"<reasoning>\" in response:\n",
    "    import re\n",
    "    response = re.sub(r\"<reasoning>.*?</reasoning>\", \"\", response, flags=re.DOTALL).strip()\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2105f330",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
