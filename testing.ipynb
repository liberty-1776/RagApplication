{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b564377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import streamlit as st\n",
    "\n",
    "## We will be suing Titan Embeddings Model To generate Embeddings\n",
    "\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_aws import ChatBedrock\n",
    "\n",
    "## Data Ingestion\n",
    "\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# Vector Embedding And Vector Store\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "## LLm Models\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86bac074",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock=boto3.client(service_name=\"bedrock-runtime\")\n",
    "bedrock_embeddings=BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",client=bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39287793",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader=PyPDFDirectoryLoader(\"data\")\n",
    "documents=loader.load()\n",
    "\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=10000,\n",
    "                                                chunk_overlap=1000)\n",
    "\n",
    "docs=text_splitter.split_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1430a3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude=ChatBedrock(model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\",client=bedrock,\n",
    "                model_kwargs={'max_tokens':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama=ChatBedrock(model_id=\"meta.llama3-70b-instruct-v1:0\",client=bedrock,\n",
    "                model_kwargs={'max_gen_len':512})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd15889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "\n",
    "Human: Use the following pieces of context to provide a \n",
    "concise answer to the question at the end but usse atleast summarize with \n",
    "250 words with detailed explaantions. If you don't know the answer, \n",
    "just say that you don't know, don't try to make up an answer.\n",
    "<context>\n",
    "{context}\n",
    "</context\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Assistant:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "643a6ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44ec75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore_faiss=FAISS.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings\n",
    ")\n",
    "vectorstore_faiss.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6faed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index = FAISS.load_local(\"faiss_index\", bedrock_embeddings,allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2be559ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "llm=claude,\n",
    "chain_type=\"stuff\",\n",
    "retriever=faiss_index.as_retriever(\n",
    "    search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "),\n",
    "return_source_documents=True,\n",
    "chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")\n",
    "answer=qa({\"query\":\"what is transformer\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1969abe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Transformer is a novel neural network architecture proposed in the paper for sequence-to-sequence tasks like machine translation. Here is a concise summary explaining the key aspects of the Transformer architecture:\\n\\nThe Transformer completely eschews recurrent layers and instead relies entirely on an attention mechanism to draw global dependencies between input and output sequences. This allows for much more parallelization than recurrent models which operate sequentially.\\n\\nThe Transformer follows an encoder-decoder architecture, but both the encoder and decoder are composed of stacked self-attention and feed-forward layers, instead of the recurrent/convolutional layers used in previous architectures.\\n\\nThe core part is the scaled dot-product attention mechanism that relates different positions of the input/output sequences to compute their representations. Multi-head attention is used to allow attending to information from different representation subspaces.\\n\\nThe Transformer uses positional encodings to incorporate order information instead of using sequential operations. It also employs residual connections around layers, layer normalization, and dropout.\\n\\nThe key advantages of the Transformer are its ability to capture long-range dependencies via self-attention while being much more parallelizable than RNNs, allowing for significant speedups in training. On machine translation tasks, the Transformer achieved a new state-of-the-art in quality while being trained much faster than previous architectures.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37f41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
